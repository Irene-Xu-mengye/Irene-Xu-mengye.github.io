library(anytime)
library(tidyverse)
pat_ID <- 2 # participant ID
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/Processed"
# read in and merge pre-processing files
load(list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms2.out"),
pattern = "*.RData", full.names = TRUE))
files_to_read <-
list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms5.outraw"),
pattern = "*.csv", recursive = TRUE, full.names = TRUE)
for (i in 1:length(files_to_read)) {
if (str_detect(files_to_read[i], "code")) {
codes <- read.csv(files_to_read[i])
} else {
raw <- read.csv(files_to_read[i]) %>%
mutate(date_time = anytime(timenum))
}
if (i > 2) {
print("WARNING: more files than expected")
}
}
# Wrangle step data
segmenting_steps <-
IMP$metashort %>%
separate(timestamp, into = c("day", "omit1", "time", "omit2"), sep = c(10, 11, 19)) %>%
select(-omit1, -omit2) %>%
unite("date_time", c("day", "time"), sep = " ") %>%
mutate(date_time = as.POSIXct(date_time)) %>%
separate(date_time, c("date", "time"), sep = " ", remove = FALSE) %>%
separate(time, c("hour", "minute", "second"), sep = ":", remove = FALSE) %>%
group_by(date, hour, minute) %>%
nest() %>%
mutate(sum_steps_vig = map_dbl(.x = data, ~sum(.x$steps_vig)),
sum_steps_nVig = map_dbl(.x = data, ~sum(.x$steps_nVig))) %>%
unnest(cols = c(data)) %>%
filter(second == "00")
View(segmenting_steps)
View(raw)
# Merge with activity types
# Code as vig if > 5 minute-bput of MVPA; otherwise, code as not vig
comb <-
raw %>%
left_join(codes) %>%
left_join(segmenting_steps) %>%
# sum if at least 5 min bout of mod-vigorous PA detected
mutate(sum_steps_final = if_else(str_detect(class_name, "MVPA_bts_10") |
str_detect(class_name, "MVPA_bts_5_10"),
sum_steps_vig, sum_steps_nVig))
View(comb)
print("WARNING: double check left join")
# Make sure merge worked as expected
if (nrow(raw) != nrow(comb)) {
print("WARNING: double check left join")
}
# output raw file with step-counts & activity types broken down by minute
minute_lvl_steps <-
comb %>% select(date_time, date, time, class_name, anglez, ENMOa, contains("sum_steps"))
if (!dir.exists(paste0(path, "/Post/output_ID_", as.character(pat_ID)))) {
dir.create(paste0(path, "/Post/output_ID_", as.character(pat_ID)))
} else {
print("Directory already exists")
}
write.csv(minute_lvl_steps,
paste0(path, "/Post/output_ID_", as.character(pat_ID), "/minute_lvl_activity.csv"),
row.names = FALSE)
# Day summaries (code book: https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html, 4.3.1)
read.csv(list.files(path = paste0(path, "/Pre/output_ID_3/results"),
pattern = "part5_daysummary*", full.names = TRUE)) %>%
# select variables most likely to be of use in analysis
select(ID:sleep_efficiency, contains("L5TIME"), contains("M5TIME"), daytype) %>%
# join with step data
left_join(comb %>%
group_by(date) %>%
summarise_at(vars(contains("sum_steps_final")), sum),
by = c("calendar_date" = "date")) %>%
# output to CSV
write.csv(., paste0(path, "/Post/output_ID_", as.character(pat_ID), "/person_lvl_summary.csv"),
row.names = FALSE)
# Summary stats & plots
QC_plot <-
comb %>%
select(date_time, date, class_name, contains("sum_steps_"), ENMOa) %>%
gather(key = key, value = value, -date_time, -class_name, -date) %>%
ggplot(., aes(x = date_time, y = value)) +
geom_point() +
geom_line() +
geom_point(y = 0, aes(color = class_name), shape = 124) +
facet_wrap(~key, scales = "free", nrow = 4) +
theme_bw() +
labs(color = "Class", y = "Steps",
title = "Evaluating actigraphy-derived step counts across different activity types",
subtitle = "Note: y-axis scales differ across subplots") +
guides(color = guide_legend(override.aes=list(shape = 15)))
# -----------------------------
# Post-processing
# -----------------------------
library(anytime)
library(tidyverse)
pat_ID <- 3 # participant ID
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/Processed"
# read in and merge pre-processing files
load(list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms2.out"),
pattern = "*.RData", full.names = TRUE))
files_to_read <-
list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms5.outraw"),
pattern = "*.csv", recursive = TRUE, full.names = TRUE)
for (i in 1:length(files_to_read)) {
if (str_detect(files_to_read[i], "code")) {
codes <- read.csv(files_to_read[i])
} else {
raw <- read.csv(files_to_read[i]) %>%
mutate(date_time = anytime(timenum))
}
if (i > 2) {
print("WARNING: more files than expected")
}
}
# Wrangle step data
segmenting_steps <-
IMP$metashort %>%
separate(timestamp, into = c("day", "omit1", "time", "omit2"), sep = c(10, 11, 19)) %>%
select(-omit1, -omit2) %>%
unite("date_time", c("day", "time"), sep = " ") %>%
mutate(date_time = as.POSIXct(date_time)) %>%
separate(date_time, c("date", "time"), sep = " ", remove = FALSE) %>%
separate(time, c("hour", "minute", "second"), sep = ":", remove = FALSE) %>%
group_by(date, hour, minute) %>%
nest() %>%
mutate(sum_steps_vig = map_dbl(.x = data, ~sum(.x$steps_vig)),
sum_steps_nVig = map_dbl(.x = data, ~sum(.x$steps_nVig))) %>%
unnest(cols = c(data)) %>%
filter(second == "00")
# Merge with activity types
# Code as vig if > 5 minute-bput of MVPA; otherwise, code as not vig
comb <-
raw %>%
left_join(codes) %>%
left_join(segmenting_steps) %>%
# sum if at least 5 min bout of mod-vigorous PA detected
mutate(sum_steps_final = if_else(str_detect(class_name, "MVPA_bts_10") |
str_detect(class_name, "MVPA_bts_5_10"),
sum_steps_vig, sum_steps_nVig))
# Make sure merge worked as expected
if (nrow(raw) != nrow(comb)) {
print("WARNING: double check left join")
}
# output raw file with step-counts & activity types broken down by minute
minute_lvl_steps <-
comb %>% select(date_time, date, time, class_name, anglez, ENMOa, contains("sum_steps"))
if (!dir.exists(paste0(path, "/Post/output_ID_", as.character(pat_ID)))) {
dir.create(paste0(path, "/Post/output_ID_", as.character(pat_ID)))
} else {
print("Directory already exists")
}
write.csv(minute_lvl_steps,
paste0(path, "/Post/output_ID_", as.character(pat_ID), "/minute_lvl_activity.csv"),
row.names = FALSE)
# Day summaries (code book: https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html, 4.3.1)
read.csv(list.files(path = paste0(path, "/Pre/output_ID_3/results"),
pattern = "part5_daysummary*", full.names = TRUE)) %>%
# select variables most likely to be of use in analysis
select(ID:sleep_efficiency, contains("L5TIME"), contains("M5TIME"), daytype) %>%
# join with step data
left_join(comb %>%
group_by(date) %>%
summarise_at(vars(contains("sum_steps_final")), sum),
by = c("calendar_date" = "date")) %>%
# output to CSV
write.csv(., paste0(path, "/Post/output_ID_", as.character(pat_ID), "/person_lvl_summary.csv"),
row.names = FALSE)
# Summary stats & plots
QC_plot <-
comb %>%
select(date_time, date, class_name, contains("sum_steps_"), ENMOa) %>%
gather(key = key, value = value, -date_time, -class_name, -date) %>%
ggplot(., aes(x = date_time, y = value)) +
geom_point() +
geom_line() +
geom_point(y = 0, aes(color = class_name), shape = 124) +
facet_wrap(~key, scales = "free", nrow = 4) +
theme_bw() +
labs(color = "Class", y = "Steps",
title = "Evaluating actigraphy-derived step counts across different activity types",
subtitle = "Note: y-axis scales differ across subplots") +
guides(color = guide_legend(override.aes=list(shape = 15)))
ggsave(paste0(path, "/Post/output_ID_", as.character(pat_ID), "/QC_plot.tiff"),
QC_plot, width = 12, height = 6)
R.version.string
R.version
install.packages("GGIR")
install.packages("GGIR")
# -----------------------------
# Post-processing
# -----------------------------
library(anytime)
library(tidyverse)
pat_ID <- 2 # participant ID
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/Processed"
# read in and merge pre-processing files
load(list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms2.out"),
pattern = "*.RData", full.names = TRUE))
files_to_read <-
list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms5.outraw"),
pattern = "*.csv", recursive = TRUE, full.names = TRUE)
for (i in 1:length(files_to_read)) {
if (str_detect(files_to_read[i], "code")) {
codes <- read.csv(files_to_read[i])
} else {
raw <- read.csv(files_to_read[i]) %>%
mutate(date_time = anytime(timenum))
}
if (i > 2) {
print("WARNING: more files than expected")
}
}
# Wrangle step data
segmenting_steps <-
IMP$metashort %>%
separate(timestamp, into = c("day", "omit1", "time", "omit2"), sep = c(10, 11, 19)) %>%
select(-omit1, -omit2) %>%
unite("date_time", c("day", "time"), sep = " ") %>%
mutate(date_time = as.POSIXct(date_time)) %>%
separate(date_time, c("date", "time"), sep = " ", remove = FALSE) %>%
separate(time, c("hour", "minute", "second"), sep = ":", remove = FALSE) %>%
group_by(date, hour, minute) %>%
nest() %>%
mutate(sum_steps_vig = map_dbl(.x = data, ~sum(.x$steps_vig)),
sum_steps_nVig = map_dbl(.x = data, ~sum(.x$steps_nVig))) %>%
unnest(cols = c(data)) %>%
filter(second == "00")
# Merge with activity types
# Code as vig if > 5 minute-bput of MVPA; otherwise, code as not vig
comb <-
raw %>%
left_join(codes) %>%
left_join(segmenting_steps) %>%
# sum if at least 5 min bout of mod-vigorous PA detected
mutate(sum_steps_final = if_else(str_detect(class_name, "MVPA_bts_10") |
str_detect(class_name, "MVPA_bts_5_10"),
sum_steps_vig, sum_steps_nVig))
# Make sure merge worked as expected
if (nrow(raw) != nrow(comb)) {
print("WARNING: double check left join")
}
# output raw file with step-counts & activity types broken down by minute
minute_lvl_steps <-
comb %>% select(date_time, date, time, class_name, anglez, ENMOa, contains("sum_steps"))
if (!dir.exists(paste0(path, "/Post/output_ID_", as.character(pat_ID)))) {
dir.create(paste0(path, "/Post/output_ID_", as.character(pat_ID)))
} else {
print("Directory already exists")
}
write.csv(minute_lvl_steps,
paste0(path, "/Post/output_ID_", as.character(pat_ID), "/minute_lvl_activity.csv"),
row.names = FALSE)
# Day summaries (code book: https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html, 4.3.1)
read.csv(list.files(path = paste0(path, "/Pre/output_ID_2/results"),
pattern = "part5_daysummary*", full.names = TRUE)) %>%
# select variables most likely to be of use in analysis
select(ID:sleep_efficiency, contains("L5TIME"), contains("M5TIME"), daytype) %>%
# join with step data
left_join(comb %>%
group_by(date) %>%
summarise_at(vars(contains("sum_steps_final")), sum),
by = c("calendar_date" = "date")) %>%
# output to CSV
write.csv(., paste0(path, "/Post/output_ID_", as.character(pat_ID), "/person_lvl_summary.csv"),
row.names = FALSE)
# Summary stats & plots
QC_plot <-
comb %>%
select(date_time, date, class_name, contains("sum_steps_"), ENMOa) %>%
gather(key = key, value = value, -date_time, -class_name, -date) %>%
ggplot(., aes(x = date_time, y = value)) +
geom_point() +
geom_line() +
geom_point(y = 0, aes(color = class_name), shape = 124) +
facet_wrap(~key, scales = "free", nrow = 4) +
theme_bw() +
labs(color = "Class", y = "Steps",
title = "Evaluating actigraphy-derived step counts across different activity types",
subtitle = "Note: y-axis scales differ across subplots") +
guides(color = guide_legend(override.aes=list(shape = 15)))
ggsave(paste0(path, "/Post/output_ID_", as.character(pat_ID), "/QC_plot.tiff"),
QC_plot, width = 12, height = 6)
# Load libraries & define function inputs
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/"
pat_ID <- 27 # participant ID
# EMA query from TMB studies DB
# select * from sittings, results
#   where sittings.id = results.sitting_id
#   and sittings.study_name in ('ts_ema', 'ts_ema_morn', 'ts_ema_onboard')
#   and sittings.user_id = 'user_id'
EMA_data <- read.csv(list.files(path = paste0(path, "Raw/ID_", as.character(pat_ID)),
pattern = "^studies.*.csv$", full.names = TRUE))
# Source functions
source(paste0(path, "ExternalFuncCode/Actigraphy_preFunc.R"))
source(paste0(path, "ExternalFuncCode/Actigraphy_postFunc.R"))
source(paste0(path, "ExternalFuncCode/wrangle_sleep.R"))
source(paste0(path, "ExternalFuncCode/parse_activity.R"))
# Wrangle sleep data
# Still debating whether to set replaceNA to TRUE vs. FALSE (or, to replace iff first night is NA)
# May come down to how many morning EMAs were missed - TBD
# With NAs, will only retain raw data for days (WW) with guiders (cf. save_ms5raw_without_invalid = TRUE in preFunc)
sleep_info <- wrangle_sleep(path = path, patID = pat_ID, EMA_data = EMA_data, replaceNA = TRUE)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
# Wrangle sleep data
# Still debating whether to set replaceNA to TRUE vs. FALSE (or, to replace iff first night is NA)
# May come down to how many morning EMAs were missed - TBD
# With NAs, will only retain raw data for days (WW) with guiders (cf. save_ms5raw_without_invalid = TRUE in preFunc)
sleep_info <- wrangle_sleep(path = path, patID = pat_ID, EMA_data = EMA_data, replaceNA = TRUE)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
library(devtools)
install_github(GENEAread)
install_github(cran/GENEAread)
install_github("cran/GENEAread")
library(GENEAread)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
install_github("wadpac/GGIR")
library(GGIR)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
source(paste0(path, "ExternalFuncCode/Actigraphy_preFunc.R"))
source(paste0(path, "ExternalFuncCode/Actigraphy_postFunc.R"))
source(paste0(path, "ExternalFuncCode/wrangle_sleep.R"))
source(paste0(path, "ExternalFuncCode/parse_activity.R"))
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
# Load libraries & define function inputs
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/"
pat_ID <- 27 # participant ID
# EMA query from TMB studies DB
# select * from sittings, results
#   where sittings.id = results.sitting_id
#   and sittings.study_name in ('ts_ema', 'ts_ema_morn', 'ts_ema_onboard')
#   and sittings.user_id = 'user_id'
EMA_data <- read.csv(list.files(path = paste0(path, "Raw/ID_", as.character(pat_ID)),
pattern = "^studies.*.csv$", full.names = TRUE))
# Source functions
source(paste0(path, "ExternalFuncCode/Actigraphy_preFunc.R"))
source(paste0(path, "ExternalFuncCode/Actigraphy_postFunc.R"))
source(paste0(path, "ExternalFuncCode/wrangle_sleep.R"))
source(paste0(path, "ExternalFuncCode/parse_activity.R"))
# Wrangle sleep data
# Still debating whether to set replaceNA to TRUE vs. FALSE (or, to replace iff first night is NA)
# May come down to how many morning EMAs were missed - TBD
# With NAs, will only retain raw data for days (WW) with guiders (cf. save_ms5raw_without_invalid = TRUE in preFunc)
sleep_info <- wrangle_sleep(path = path, patID = pat_ID, EMA_data = EMA_data, replaceNA = TRUE)
# Load libraries & define function inputs
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/"
pat_ID <- 27 # participant ID
# EMA query from TMB studies DB
# select * from sittings, results
#   where sittings.id = results.sitting_id
#   and sittings.study_name in ('ts_ema', 'ts_ema_morn', 'ts_ema_onboard')
#   and sittings.user_id = 'user_id'
EMA_data <- read.csv(list.files(path = paste0(path, "Raw/ID_", as.character(pat_ID)),
pattern = "^studies.*.csv$", full.names = TRUE))
# Source functions
source(paste0(path, "ExternalFuncCode/Actigraphy_preFunc.R"))
source(paste0(path, "ExternalFuncCode/Actigraphy_postFunc.R"))
source(paste0(path, "ExternalFuncCode/wrangle_sleep.R"))
source(paste0(path, "ExternalFuncCode/parse_activity.R"))
# Wrangle sleep data
# Still debating whether to set replaceNA to TRUE vs. FALSE (or, to replace iff first night is NA)
# May come down to how many morning EMAs were missed - TBD
# With NAs, will only retain raw data for days (WW) with guiders (cf. save_ms5raw_without_invalid = TRUE in preFunc)
sleep_info <- wrangle_sleep(path = path, patID = pat_ID, EMA_data = EMA_data, replaceNA = TRUE)
# Wrangle sleep data
# Still debating whether to set replaceNA to TRUE vs. FALSE (or, to replace iff first night is NA)
# May come down to how many morning EMAs were missed - TBD
# With NAs, will only retain raw data for days (WW) with guiders (cf. save_ms5raw_without_invalid = TRUE in preFunc)
sleep_info <- wrangle_sleep(path = path, patID = pat_ID, EMA_data = EMA_data, replaceNA = TRUE)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
# Post-processing
actigraphy_postP(path = path, patID = pat_ID, output_plot = TRUE)
# EMA-level activity data
parse_activity(path = path, patID = pat_ID, EMA_data = EMA_data,
direction = -1, offset_min = c(5, 20, 60, 180),
steps = TRUE, activity = TRUE, export = TRUE, return = FALSE)
rmarkdown::render_site("www/")
setwd("~/Documents/GitHub/Irene-Xu-mengye.github.io")
rmarkdown::render_site("www/")
install.packages('blogdown')
setwd("~/Documents/GitHub/personal-website/www")
rmarkdown::render_site(“www”)
rmarkdown::render_site("www")
setwd("~/Documents/GitHub/personal-website/")
rmarkdown::render_site("www")
rmarkdown::render_site("www")
rmarkdown::render_site("www")
rmarkdown::render_site("www")
rmarkdown::render_site("www")
rmarkdown::render_site("www")
# Load libraries ------------
library(backports)     # to revive the isFALSE() function for sim_slopes()
library(effects)       # for probing interactions
library(ggplot2)       # for data visualization
library(interactions)  # for probing/plotting interactions
library(lme4)          # for multilevel models
library(lmerTest)      # for p-values
library(psych)         # for describing the data
library(plyr)          # for data manipulation
library(tidyverse)
# Load data ---------------
# Loading person-level file (N = 190) and subsetting to variables of interest
filepath <- "https://quantdev.ssri.psu.edu/sites/qdev/files/AMIBshare_persons_2019_0501.csv"
# read in the .csv file using the url() function
AMIB_persons <- read.csv(file=url(filepath),header=TRUE)
# subsetting to variables of interest
AMIB_persons <- AMIB_persons[ ,c("id","bfi_n")]
# Loading person-level file (N = 190) and subsetting to variables of interest
filepath <- "https://quantdev.ssri.psu.edu/sites/qdev/files/AMIBshare_persons_2019_0501.csv"
# read in the .csv file using the url() function
AMIB_persons <- read.csv(file=url(filepath),header=TRUE)
# subsetting to variables of interest
AMIB_persons <- AMIB_persons[ ,c("id","bfi_n")]
# Loading person-level file (N = 190) and subsetting to variables of interest
filepath <- "https://quantdev.ssri.psu.edu/sites/qdev/files/AMIBshare_persons_2019_0501.csv"
# read in the .csv file using the url() function
AMIB_persons <- read.csv(file=url(filepath),header=TRUE)
# subsetting to variables of interest
AMIB_persons <- AMIB_persons[ ,c("id","bfi_n")]
View(AMIB_persons)
# Loading day-level file (T = 8) and subsetting to variables of interest.
filepath <- "https://quantdev.ssri.psu.edu/sites/qdev/files/AMIBshare_daily_2019_0501.csv"
AMIB_daily <- read.csv(file=url(filepath),header=TRUE)
# subsetting to variables of interest
AMIB_daily <- AMIB_daily[ ,c("id","day","negaff","pss")]
View(AMIB_daily)
## Data Recoding ------
# Reverse code pss into a new stress variable where higher values indicate higher perceived stress.
# reverse coding the pss variable into a new stress variable
AMIB_daily$stress <- 4 - AMIB_daily$pss
# describing new variable
describe(AMIB_daily$stress)
#histogram
ggplot(data=AMIB_daily, aes(x=stress)) +
geom_histogram(fill="white", color="black",bins=20) +
labs(x = "Stress (high = more stressed)")
# calculating intraindividual means
AMIB_imeans <- AMIB_daily %>%
group_by(id) %>%
dplyr::summarize(stress_trait = mean(stress, na.rm = TRUE),
negaff_trait = mean(negaff, na.rm=TRUE))
describe(AMIB_imeans)
View(AMIB_imeans)
# merging into person-level file
AMIB_persons <- merge(AMIB_persons, AMIB_imeans, by="id")
# make centered versions of the person-level scores
AMIB_persons$bfi_n_c <- scale(AMIB_persons$bfi_n, center = TRUE, scale = TRUE)
AMIB_persons$stress_trait_c <- scale(AMIB_persons$stress_trait, center = TRUE,scale = FALSE)
describe(AMIB_persons)
AMIB_persons$stress_trait_c <- scale(AMIB_persons$stress_trait, center = TRUE,scale = FALSE)
describe(AMIB_persons)
# make centered versions of the person-level scores
AMIB_persons$bfi_n_c <- scale(AMIB_persons$bfi_n,center=TRUE,scale=FALSE)
AMIB_persons$stress_trait_c <- scale(AMIB_persons$stress_trait,center=TRUE,scale=FALSE)
describe(AMIB_persons)
### Making state variables in long data -----------
# (as deviations from uncentered trait variable).
# merging person-level data into daily data
daily_long <- merge(AMIB_daily,AMIB_persons,by="id")
# calculating state variables
daily_long$stress_state <- daily_long$stress - daily_long$stress_trait
daily_long$negaff_state <- daily_long$negaff - daily_long$negaff_trait
daily_long$negaff_state <- daily_long$negaff - daily_long$negaff_trait
describe(daily_long)
## Unconditional means model ----------------------------
model0_fit <- lmer(formula = negaff ~ 1 + (1|id),
data=daily_long,
na.action=na.exclude)
summary(model0_fit)
# We extract the random effects with the VarCorr() function:
VarCorr(model0_fit)
# Load data ---------------
# Loading person-level file (N = 190) and subsetting to variables of interest
filepath <- "https://quantdev.ssri.psu.edu/sites/qdev/files/AMIBshare_persons_2019_0501.csv"
# read in the .csv file using the url() function
AMIB_persons <- read.csv(file=url(filepath),header=TRUE)
# subsetting to variables of interest
AMIB_persons <- AMIB_persons[ ,c("id","bfi_n")]
# merging into person-level file
AMIB_persons <- merge(AMIB_persons, AMIB_imeans, by="id")
