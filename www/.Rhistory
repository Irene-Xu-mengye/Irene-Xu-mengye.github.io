threshold.mod = (645/(80*60)) * 1000,
threshold.vig = (1810/(80*60)) * 1000,
mvpathreshold = (645/(80*60)) * 1000,
save_ms5rawlevels = TRUE,
part5_agg2_60seconds = TRUE,
save_ms5raw_without_invalid = TRUE,
# ----------------
do.report = c(2, 4, 5),
timewindow = c("WW"),
visualreport = TRUE,
dofirstpage = TRUE,
myfun=vcs_fun # implement step count algorithm from external function
)
# -----------------------------
# Post-processing
# -----------------------------
library(anytime)
library(tidyverse)
pat_ID <- 2 # participant ID
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/Processed"
# read in and merge pre-processing files
load(list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms2.out"),
pattern = "*.RData", full.names = TRUE))
files_to_read <-
list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms5.outraw"),
pattern = "*.csv", recursive = TRUE, full.names = TRUE)
for (i in 1:length(files_to_read)) {
if (str_detect(files_to_read[i], "code")) {
codes <- read.csv(files_to_read[i])
} else {
raw <- read.csv(files_to_read[i]) %>%
mutate(date_time = anytime(timenum))
}
if (i > 2) {
print("WARNING: more files than expected")
}
}
# Wrangle step data
segmenting_steps <-
IMP$metashort %>%
separate(timestamp, into = c("day", "omit1", "time", "omit2"), sep = c(10, 11, 19)) %>%
select(-omit1, -omit2) %>%
unite("date_time", c("day", "time"), sep = " ") %>%
mutate(date_time = as.POSIXct(date_time)) %>%
separate(date_time, c("date", "time"), sep = " ", remove = FALSE) %>%
separate(time, c("hour", "minute", "second"), sep = ":", remove = FALSE) %>%
group_by(date, hour, minute) %>%
nest() %>%
mutate(sum_steps_vig = map_dbl(.x = data, ~sum(.x$steps_vig)),
sum_steps_nVig = map_dbl(.x = data, ~sum(.x$steps_nVig))) %>%
unnest(cols = c(data)) %>%
filter(second == "00")
View(segmenting_steps)
View(raw)
# Merge with activity types
# Code as vig if > 5 minute-bput of MVPA; otherwise, code as not vig
comb <-
raw %>%
left_join(codes) %>%
left_join(segmenting_steps) %>%
# sum if at least 5 min bout of mod-vigorous PA detected
mutate(sum_steps_final = if_else(str_detect(class_name, "MVPA_bts_10") |
str_detect(class_name, "MVPA_bts_5_10"),
sum_steps_vig, sum_steps_nVig))
View(comb)
print("WARNING: double check left join")
# Make sure merge worked as expected
if (nrow(raw) != nrow(comb)) {
print("WARNING: double check left join")
}
# output raw file with step-counts & activity types broken down by minute
minute_lvl_steps <-
comb %>% select(date_time, date, time, class_name, anglez, ENMOa, contains("sum_steps"))
if (!dir.exists(paste0(path, "/Post/output_ID_", as.character(pat_ID)))) {
dir.create(paste0(path, "/Post/output_ID_", as.character(pat_ID)))
} else {
print("Directory already exists")
}
write.csv(minute_lvl_steps,
paste0(path, "/Post/output_ID_", as.character(pat_ID), "/minute_lvl_activity.csv"),
row.names = FALSE)
# Day summaries (code book: https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html, 4.3.1)
read.csv(list.files(path = paste0(path, "/Pre/output_ID_3/results"),
pattern = "part5_daysummary*", full.names = TRUE)) %>%
# select variables most likely to be of use in analysis
select(ID:sleep_efficiency, contains("L5TIME"), contains("M5TIME"), daytype) %>%
# join with step data
left_join(comb %>%
group_by(date) %>%
summarise_at(vars(contains("sum_steps_final")), sum),
by = c("calendar_date" = "date")) %>%
# output to CSV
write.csv(., paste0(path, "/Post/output_ID_", as.character(pat_ID), "/person_lvl_summary.csv"),
row.names = FALSE)
# Summary stats & plots
QC_plot <-
comb %>%
select(date_time, date, class_name, contains("sum_steps_"), ENMOa) %>%
gather(key = key, value = value, -date_time, -class_name, -date) %>%
ggplot(., aes(x = date_time, y = value)) +
geom_point() +
geom_line() +
geom_point(y = 0, aes(color = class_name), shape = 124) +
facet_wrap(~key, scales = "free", nrow = 4) +
theme_bw() +
labs(color = "Class", y = "Steps",
title = "Evaluating actigraphy-derived step counts across different activity types",
subtitle = "Note: y-axis scales differ across subplots") +
guides(color = guide_legend(override.aes=list(shape = 15)))
# -----------------------------
# Post-processing
# -----------------------------
library(anytime)
library(tidyverse)
pat_ID <- 3 # participant ID
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/Processed"
# read in and merge pre-processing files
load(list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms2.out"),
pattern = "*.RData", full.names = TRUE))
files_to_read <-
list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms5.outraw"),
pattern = "*.csv", recursive = TRUE, full.names = TRUE)
for (i in 1:length(files_to_read)) {
if (str_detect(files_to_read[i], "code")) {
codes <- read.csv(files_to_read[i])
} else {
raw <- read.csv(files_to_read[i]) %>%
mutate(date_time = anytime(timenum))
}
if (i > 2) {
print("WARNING: more files than expected")
}
}
# Wrangle step data
segmenting_steps <-
IMP$metashort %>%
separate(timestamp, into = c("day", "omit1", "time", "omit2"), sep = c(10, 11, 19)) %>%
select(-omit1, -omit2) %>%
unite("date_time", c("day", "time"), sep = " ") %>%
mutate(date_time = as.POSIXct(date_time)) %>%
separate(date_time, c("date", "time"), sep = " ", remove = FALSE) %>%
separate(time, c("hour", "minute", "second"), sep = ":", remove = FALSE) %>%
group_by(date, hour, minute) %>%
nest() %>%
mutate(sum_steps_vig = map_dbl(.x = data, ~sum(.x$steps_vig)),
sum_steps_nVig = map_dbl(.x = data, ~sum(.x$steps_nVig))) %>%
unnest(cols = c(data)) %>%
filter(second == "00")
# Merge with activity types
# Code as vig if > 5 minute-bput of MVPA; otherwise, code as not vig
comb <-
raw %>%
left_join(codes) %>%
left_join(segmenting_steps) %>%
# sum if at least 5 min bout of mod-vigorous PA detected
mutate(sum_steps_final = if_else(str_detect(class_name, "MVPA_bts_10") |
str_detect(class_name, "MVPA_bts_5_10"),
sum_steps_vig, sum_steps_nVig))
# Make sure merge worked as expected
if (nrow(raw) != nrow(comb)) {
print("WARNING: double check left join")
}
# output raw file with step-counts & activity types broken down by minute
minute_lvl_steps <-
comb %>% select(date_time, date, time, class_name, anglez, ENMOa, contains("sum_steps"))
if (!dir.exists(paste0(path, "/Post/output_ID_", as.character(pat_ID)))) {
dir.create(paste0(path, "/Post/output_ID_", as.character(pat_ID)))
} else {
print("Directory already exists")
}
write.csv(minute_lvl_steps,
paste0(path, "/Post/output_ID_", as.character(pat_ID), "/minute_lvl_activity.csv"),
row.names = FALSE)
# Day summaries (code book: https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html, 4.3.1)
read.csv(list.files(path = paste0(path, "/Pre/output_ID_3/results"),
pattern = "part5_daysummary*", full.names = TRUE)) %>%
# select variables most likely to be of use in analysis
select(ID:sleep_efficiency, contains("L5TIME"), contains("M5TIME"), daytype) %>%
# join with step data
left_join(comb %>%
group_by(date) %>%
summarise_at(vars(contains("sum_steps_final")), sum),
by = c("calendar_date" = "date")) %>%
# output to CSV
write.csv(., paste0(path, "/Post/output_ID_", as.character(pat_ID), "/person_lvl_summary.csv"),
row.names = FALSE)
# Summary stats & plots
QC_plot <-
comb %>%
select(date_time, date, class_name, contains("sum_steps_"), ENMOa) %>%
gather(key = key, value = value, -date_time, -class_name, -date) %>%
ggplot(., aes(x = date_time, y = value)) +
geom_point() +
geom_line() +
geom_point(y = 0, aes(color = class_name), shape = 124) +
facet_wrap(~key, scales = "free", nrow = 4) +
theme_bw() +
labs(color = "Class", y = "Steps",
title = "Evaluating actigraphy-derived step counts across different activity types",
subtitle = "Note: y-axis scales differ across subplots") +
guides(color = guide_legend(override.aes=list(shape = 15)))
ggsave(paste0(path, "/Post/output_ID_", as.character(pat_ID), "/QC_plot.tiff"),
QC_plot, width = 12, height = 6)
R.version.string
R.version
install.packages("GGIR")
install.packages("GGIR")
# -----------------------------
# Post-processing
# -----------------------------
library(anytime)
library(tidyverse)
pat_ID <- 2 # participant ID
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/Processed"
# read in and merge pre-processing files
load(list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms2.out"),
pattern = "*.RData", full.names = TRUE))
files_to_read <-
list.files(path = paste0(path, "/Pre/output_ID_", as.character(pat_ID), "/meta/ms5.outraw"),
pattern = "*.csv", recursive = TRUE, full.names = TRUE)
for (i in 1:length(files_to_read)) {
if (str_detect(files_to_read[i], "code")) {
codes <- read.csv(files_to_read[i])
} else {
raw <- read.csv(files_to_read[i]) %>%
mutate(date_time = anytime(timenum))
}
if (i > 2) {
print("WARNING: more files than expected")
}
}
# Wrangle step data
segmenting_steps <-
IMP$metashort %>%
separate(timestamp, into = c("day", "omit1", "time", "omit2"), sep = c(10, 11, 19)) %>%
select(-omit1, -omit2) %>%
unite("date_time", c("day", "time"), sep = " ") %>%
mutate(date_time = as.POSIXct(date_time)) %>%
separate(date_time, c("date", "time"), sep = " ", remove = FALSE) %>%
separate(time, c("hour", "minute", "second"), sep = ":", remove = FALSE) %>%
group_by(date, hour, minute) %>%
nest() %>%
mutate(sum_steps_vig = map_dbl(.x = data, ~sum(.x$steps_vig)),
sum_steps_nVig = map_dbl(.x = data, ~sum(.x$steps_nVig))) %>%
unnest(cols = c(data)) %>%
filter(second == "00")
# Merge with activity types
# Code as vig if > 5 minute-bput of MVPA; otherwise, code as not vig
comb <-
raw %>%
left_join(codes) %>%
left_join(segmenting_steps) %>%
# sum if at least 5 min bout of mod-vigorous PA detected
mutate(sum_steps_final = if_else(str_detect(class_name, "MVPA_bts_10") |
str_detect(class_name, "MVPA_bts_5_10"),
sum_steps_vig, sum_steps_nVig))
# Make sure merge worked as expected
if (nrow(raw) != nrow(comb)) {
print("WARNING: double check left join")
}
# output raw file with step-counts & activity types broken down by minute
minute_lvl_steps <-
comb %>% select(date_time, date, time, class_name, anglez, ENMOa, contains("sum_steps"))
if (!dir.exists(paste0(path, "/Post/output_ID_", as.character(pat_ID)))) {
dir.create(paste0(path, "/Post/output_ID_", as.character(pat_ID)))
} else {
print("Directory already exists")
}
write.csv(minute_lvl_steps,
paste0(path, "/Post/output_ID_", as.character(pat_ID), "/minute_lvl_activity.csv"),
row.names = FALSE)
# Day summaries (code book: https://cran.r-project.org/web/packages/GGIR/vignettes/GGIR.html, 4.3.1)
read.csv(list.files(path = paste0(path, "/Pre/output_ID_2/results"),
pattern = "part5_daysummary*", full.names = TRUE)) %>%
# select variables most likely to be of use in analysis
select(ID:sleep_efficiency, contains("L5TIME"), contains("M5TIME"), daytype) %>%
# join with step data
left_join(comb %>%
group_by(date) %>%
summarise_at(vars(contains("sum_steps_final")), sum),
by = c("calendar_date" = "date")) %>%
# output to CSV
write.csv(., paste0(path, "/Post/output_ID_", as.character(pat_ID), "/person_lvl_summary.csv"),
row.names = FALSE)
# Summary stats & plots
QC_plot <-
comb %>%
select(date_time, date, class_name, contains("sum_steps_"), ENMOa) %>%
gather(key = key, value = value, -date_time, -class_name, -date) %>%
ggplot(., aes(x = date_time, y = value)) +
geom_point() +
geom_line() +
geom_point(y = 0, aes(color = class_name), shape = 124) +
facet_wrap(~key, scales = "free", nrow = 4) +
theme_bw() +
labs(color = "Class", y = "Steps",
title = "Evaluating actigraphy-derived step counts across different activity types",
subtitle = "Note: y-axis scales differ across subplots") +
guides(color = guide_legend(override.aes=list(shape = 15)))
ggsave(paste0(path, "/Post/output_ID_", as.character(pat_ID), "/QC_plot.tiff"),
QC_plot, width = 12, height = 6)
# Load libraries & define function inputs
path <- "~/Dropbox (Partners HealthCare)/Threat NIMH R01/GeneActiv/GGIR/"
pat_ID <- 27 # participant ID
# EMA query from TMB studies DB
# select * from sittings, results
#   where sittings.id = results.sitting_id
#   and sittings.study_name in ('ts_ema', 'ts_ema_morn', 'ts_ema_onboard')
#   and sittings.user_id = 'user_id'
EMA_data <- read.csv(list.files(path = paste0(path, "Raw/ID_", as.character(pat_ID)),
pattern = "^studies.*.csv$", full.names = TRUE))
# Source functions
source(paste0(path, "ExternalFuncCode/Actigraphy_preFunc.R"))
source(paste0(path, "ExternalFuncCode/Actigraphy_postFunc.R"))
source(paste0(path, "ExternalFuncCode/wrangle_sleep.R"))
source(paste0(path, "ExternalFuncCode/parse_activity.R"))
# Wrangle sleep data
# Still debating whether to set replaceNA to TRUE vs. FALSE (or, to replace iff first night is NA)
# May come down to how many morning EMAs were missed - TBD
# With NAs, will only retain raw data for days (WW) with guiders (cf. save_ms5raw_without_invalid = TRUE in preFunc)
sleep_info <- wrangle_sleep(path = path, patID = pat_ID, EMA_data = EMA_data, replaceNA = TRUE)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
# Wrangle sleep data
# Still debating whether to set replaceNA to TRUE vs. FALSE (or, to replace iff first night is NA)
# May come down to how many morning EMAs were missed - TBD
# With NAs, will only retain raw data for days (WW) with guiders (cf. save_ms5raw_without_invalid = TRUE in preFunc)
sleep_info <- wrangle_sleep(path = path, patID = pat_ID, EMA_data = EMA_data, replaceNA = TRUE)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
library(devtools)
install_github(GENEAread)
install_github(cran/GENEAread)
install_github("cran/GENEAread")
library(GENEAread)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
install_github("wadpac/GGIR")
library(GGIR)
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
source(paste0(path, "ExternalFuncCode/Actigraphy_preFunc.R"))
source(paste0(path, "ExternalFuncCode/Actigraphy_postFunc.R"))
source(paste0(path, "ExternalFuncCode/wrangle_sleep.R"))
source(paste0(path, "ExternalFuncCode/parse_activity.R"))
# Pre-processing
# Still evaluating whether parameters passed to myscript.R effectively estimate vig steps
actigraphy_preP(path = path, patID = pat_ID,
nights_info = sleep_info[[1]],
hrs_del_start = sleep_info[[2]],
hrs_del_end = sleep_info[[3]])
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
#load library
library(tidyverse)
library(psych)
library(DT)
df <- read.csv("choiceRT_results_legacy_id1056.csv")
source("json_splitter.R")
View(df)
df <- read.csv("choiceRT_results_legacy_id1056.csv")
source("https://www.dropbox.com/s/bmhdm3d5xa7j7oa/json_splitter.R?raw=1")
df1 <- deJSON.data(df) # this takes a while
View(df)
View(df1)
unique(df1$type)
df2 <- df1 %>%
filter(type == "test") %>%
select(id, type, correct, rt)
View(df2)
df2 <- df1 %>%
filter(type == "test") %>%
select(id, correct, rt)
df2 <- df1 %>%
filter(type == "test") %>%
select(id, correct, rt) %>%
group_by(id) %>%
mutate(trial = row_number())
View(df2)
9/5
9%5
9 %% 5
df2 <- df1 %>%
filter(type == "test") %>%
select(id, correct, rt) %>%
group_by(id) %>%
mutate(trial = row_number(),
half = ifelse(trial %% 2 == 1, "odd", "even"))
View(df2)
df2 <- df1 %>%
filter(type == "test") %>%
select(id, correct, rt) %>%
group_by(id) %>%
mutate(trial = row_number(),
half = ifelse(trial %% 2 == 1, "odd", "even")) %>%
group_by(id, half)
View(df2)
df2 <- df1 %>%
filter(type == "test" &  correct == 1) %>%
select(id, rt) %>%
group_by(id) %>%
mutate(trial = row_number(),
half = ifelse(trial %% 2 == 1, "odd", "even"))
View(df2)
df2 <- df1 %>%
filter(type == "test" &  correct == 1) %>%
select(id, rt) %>%
group_by(id) %>%
mutate(trial = row_number(),
half = ifelse(trial %% 2 == 1, "odd", "even")) %>%
group_by(id, half) %>%
summarise(med_rt = median(rt))
df2 <- df1 %>%
filter(type == "test" &  correct == 1) %>%
select(id, rt) %>%
group_by(id) %>%
mutate(trial = row_number(),
half = ifelse(trial %% 2 == 1, "odd", "even"),
rt = as.numeric(rt)) %>%
group_by(id, half) %>%
summarise(med_rt = median(rt))
View(df2)
df2 <- df1 %>%
filter(type == "test" &  correct == 1) %>%
select(id, rt) %>%
group_by(id) %>%
mutate(trial = row_number(),
half = ifelse(trial %% 2 == 1, "odd", "even"),
rt = as.numeric(rt)) %>%
group_by(id, half) %>%
summarise(med_rt = median(rt)) %>%
pivot_wider(names_from = half, values_from = med_rt)
View(df2)
cor.test(df2$even, df2$odd)
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.7)
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", size = 3, alpha = 0.7)
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.4)
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.1)
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.2)
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.2) +
theme_minimal()
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.2, size = 0.3) +
theme_minimal()
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.7, size = 0.3) +
theme_minimal()
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.7, size = 0.5) +
theme_minimal()
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.7, size = 0.4) +
theme_minimal()
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.6, size = 0.4) +
theme_minimal()
ggplot(df2, aes(x = odd, y = even)) +
geom_point(color = "deepskyblue4", alpha = 0.6, size = 0.5) +
theme_minimal()
df3 <- df1 %>%
filter(type == "test") %>%
select(id, correct) %>%
group_by(id) %>%
mutate(trial = row_number(),
half = ifelse(trial %% 2 == 1, "odd", "even")) %>%
group_by(id, half)
View(df3)
(1+1+1+0)/4
mean(1+1+1+0)
mean(1,1,1,0)
max(c$vrt_ir_raw, na.rm=TRUE)
knitr::opts_chunk$set(warning=FALSE, message=FALSE, echo=FALSE, fig.width = 10, fig.height = 20)
library(tidyverse)
library(gridExtra)
source("../data_processing/gmdd/gmdd_fun.R")
alldata <- read_csv("../data/gmdd/gmdd_042222.csv")
c <- alldata %>% filter(arm == "Control")
m <- alldata %>% filter(arm == "Mood")
control <- c %>%
group_by(visit) %>%
dplyr::summarise(n = n())
mood <- m %>%
group_by(visit) %>%
dplyr::summarise(n = n())
max(c$vrt_ir_raw, na.rm=TRUE)
rmarkdown::render_site("index.rmd")
setwd("~/Documents/GitHub/personal-website/www")
rmarkdown::render_site("index.rmd")
rmarkdown::render_site("about.rmd")
rmarkdown::render_site("about.rmd")
rmarkdown::render_site("about.rmd")
